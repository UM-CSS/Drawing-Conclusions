{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSS Lab: Drawing Conclusions\n",
    "This lab covers techniques for evaluating the validity of conclusions made from data. These conclusions are not always clear, and can have ethical implications. After completing this lab, you will understand some of the factors and methods used to evaluate the conclusions reached from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Background\n",
    "This lab uses data from the University of Michigan Learning Analytics Data Architecture (LARC) project. The LARC project tracks the performance of all undergraduate students at the University of Michigan. To protect the privacy of students, the true data is used to generate a synthetic data set: fake data that preserves the statistical properties of the original data. This data can be used to investigate questions about the performance of students over the course of their undergraduate career, taking factors such as major, gender, and year into account.\n",
    "\n",
    "## Section 2: Setup\n",
    "### 2.1 Load Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats as spstats\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load Data\n",
    "We begin by loading data about each (synthetic) student, and using the anonymous ID column (ANONID) as an index for the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student = pd.read_csv(\"data/student.record.csv.gz\").set_index(\"ANONID\")\n",
    "df_student.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading course data\n",
    "Now we load a separate data frame containing one row for each student/course combination. Some of the columns in this data frame are:\n",
    "\n",
    "* TERM - Academic term id\n",
    "* ANONID - Student id\n",
    "* SUBJECT - Course academic subject\n",
    "* CATALOG_NBR - Course catalog number (not unique across subjects)\n",
    "* GRADE - Student's grade in course\n",
    "* GPAO - Student's GPA up to and including current semester, excluding this course.\n",
    "* Season - Academic term season\n",
    "* Year - Acadeic term year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_course = pd.read_csv(\"data/course-modified.csv.gz\")\n",
    "df_course.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining Data\n",
    "Let's plot the high school GPAs of all students in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "df_student.HSGPA.hist(bins=np.arange(0.01,37.01))\n",
    "plt.xlabel('High School GPA'); plt.ylabel('Count')\n",
    "plt.yscale('log', nonposy='clip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 1\n",
    "The highest possible GPA is 4.0, but the above plot shows values above 30.\n",
    "These values must be errors. Give at least two possible explanations for how a value of 31 could end up in a student's gpa record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤” Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data\n",
    "We can do some data cleaning to remove values that are obvious errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "outliers = df_student.HSGPA > 4\n",
    "df_student.loc[outliers] = None\n",
    "# Remove missing data coded as 0\n",
    "missing = df_student.HSGPA == 0\n",
    "df_student.loc[missing] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "df_student.HSGPA.hist(bins=25)\n",
    "plt.xlabel('High School GPA'); plt.ylabel('Count')\n",
    "plt.yscale('log', nonposy='clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# More data cleaning\n",
    "\n",
    "outliers = df_course.GRADE > 4\n",
    "df_course.loc[outliers] = None\n",
    "missing = np.isnan(df_course.GRADE)\n",
    "df_course = df_course.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Combining Data\n",
    "We can join the student and course data into a single data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_course.join(df_student, on=\"ANONID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Sampling\n",
    "Often, data is collected from a small group in order to try to understand a larger group. For example, asking 100 random students to complete a survey in order to understand the entire student body. This process is called _sampling_. The data collected is called the ___sample___ and the larger group is the ___target population___."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def get_bins(values):\n",
    "    values = sorted(set(values))\n",
    "    midpoints = [np.mean((values[i],values[i+1])) for i, g in enumerate(values[:-1])]\n",
    "    left = values[0] - (midpoints[0] - values[0])\n",
    "    right = values[-1] + (values[-1] - midpoints[-1])\n",
    "    bins = [left] + midpoints + [right]\n",
    "    return bins\n",
    "\n",
    "grade_hist_bins = get_bins(df_course.GRADE)\n",
    "all_grades = sorted(set(df_course.GRADE))\n",
    "\n",
    "def get_sample_mean(df, num_samples=10):\n",
    "    samples = df.GRADE.dropna().sample(num_samples, replace=True)\n",
    "    return samples.mean()\n",
    "\n",
    "def grade_hist(grades, color=(0,0,1,0.5)):\n",
    "    n, bins, patches = plt.hist(grades, align=\"mid\", bins=grade_hist_bins, width=0.1, color=color)\n",
    "    plt.xticks(range(5), ['E', 'D', 'C', 'B', 'A'])\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(\"Grade\")\n",
    "    \n",
    "def grade_stem(grades, color=(0,0,1,0.5)):\n",
    "    bin_values, bins = np.histogram(grades, grade_hist_bins)\n",
    "    plt.stem(all_grades, bin_values, basefmt=\"none\")\n",
    "    plt.xticks(range(5), ['E', 'D', 'C', 'B', 'A'])\n",
    "    ylim = plt.ylim()\n",
    "    plt.ylim([0, ylim[1]])\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(\"Grade\")\n",
    "\n",
    "def compare_populations(\n",
    "        a, b,\n",
    "        num_samples=10,\n",
    "        num_experiments=1000,\n",
    "        bins=20,\n",
    "        rwidth=1,\n",
    "        color=(0,0,1,0.5),\n",
    "        confidence=None):\n",
    "    a_mean = []\n",
    "    pop_mean = b.GRADE.mean()\n",
    "    for i in range(num_experiments):\n",
    "        a_mean.append(get_sample_mean(a, num_samples))\n",
    "    n, bins, patches = plt.hist(a_mean, bins=bins, rwidth=rwidth, color=color)\n",
    "    plt.plot([pop_mean, pop_mean], [0, max(n)], \"--\", color=\"#7f7f7f\")\n",
    "    if confidence is not None:\n",
    "        maxbin, maxcount = max(enumerate(n), key=lambda x: x[1])\n",
    "        low = maxbin\n",
    "        count = 1\n",
    "        odd = False\n",
    "        while sum(n[low:(low + count)]) < confidence * sum(n):\n",
    "            lastlow = low\n",
    "            lastcount = count\n",
    "            if odd:\n",
    "                high = low + count\n",
    "                low = max(0, low - 1)\n",
    "                count = high - low\n",
    "                odd = False\n",
    "            else:\n",
    "                count = min(len(n) - low, count + 1)\n",
    "                odd = True\n",
    "        lowx = bins[lastlow]\n",
    "        highx = bins[lastlow + lastcount]\n",
    "        plt.plot([lowx, lowx], [0, max(n)], \":\", color=\"#7f7f7f\")\n",
    "        plt.plot([highx, highx], [0, max(n)], \":\", color=\"#7f7f7f\")        \n",
    "    plt.xticks(range(5), ['E', 'D', 'C', 'B', 'A'])\n",
    "    plt.ylabel(\"Number of experiments\")\n",
    "    plt.legend()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Sample Size\n",
    "\n",
    "#### Population Mean\n",
    "In this section, we will use the example of finding the mean course grade of students in the LARC data set. Since we have data on all students rather than just a sample, we can calculate the exact mean of all students, called the ___population mean___, but usually that's not possible. The cell below calculates the exact mean, which will be helpful to keep in mind throught this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mean = df_course.GRADE.mean()\n",
    "pop_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling\n",
    "Now let's pretend we only have access to a sample and try to infer the mean of the population (all students) from the sample. The below cell simulates an experiment that samples three random course grades and calculates their mean, called the ___sample mean___. The figure shows the grades sampled and is labeled with the sample mean. You can repeat this cell to see different random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 3\n",
    "samples = df_course.GRADE.sample(sample_size)\n",
    "plt.figure(figsize=(8,4))\n",
    "grade_stem(samples)\n",
    "plt.title(\"Sample mean: {:0.2f}\".format(np.mean(samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Mean\n",
    "The cell below re-samples 10 times and finds the mean of each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "for i in range(10):\n",
    "    m = df_course.GRADE.sample(sample_size).mean()\n",
    "    means.append(m)\n",
    "    print(\"Sample {} mean: {:0.2f}\".format(i ,m))\n",
    "print(\"Sample mean range: {:0.2f} â€” {:0.2f}\".format(min(means), max(means)))\n",
    "print(\"Population mean: {:0.2f}\".format(pop_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 2\n",
    "What is the size of the range between the lowest and highest sample means?\n",
    "\n",
    "Which letter grade or grades does this range correspond to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increasing Sample Size\n",
    "Now, let's imagine you got a grant that allows you to sample a much larger number of students. The cell below samples 200 students to estimate the mean course grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 200\n",
    "samples = df_course.GRADE.sample(sample_size)\n",
    "plt.figure(figsize=(8,4))\n",
    "grade_stem(samples)\n",
    "plt.title(\"Sample mean: {:0.2f}\".format(np.mean(samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeated Measurements\n",
    "Using the new sample size of 200, the below cell calculates the sample mean of 10 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "for i in range(10):\n",
    "    m = df_course.GRADE.sample(sample_size).mean()\n",
    "    means.append(m)\n",
    "    print(\"Sample {} mean: {:0.2f}\".format(i, m))\n",
    "print(\"Range: {:0.2f} â€” {:0.2f}\".format(min(means), max(means)))\n",
    "print(\"Population mean: {:0.2f}\".format(pop_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 3\n",
    "What is the size of the range between the lowest and highest sample means?\n",
    "\n",
    "How does sample size affect the range of sample means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Sample Bias\n",
    "In the previous section, we saw that estimates based on samples depend on the size of the sample. In this section, we explore what happens if a sample is drawn from a subset the population, rather than the entire population. For comparison, the cell below shows the true population mean of all course grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Frame\n",
    "The ___sampling frame___ is the set of possible samples. Ideally, the sampling frame should be the entire population, but that may not always be possible.\n",
    "\n",
    "As an example, let's assume that we're conducting a survey of student grades and are sampling student names from SAT records. Not all students took the SAT. So it will not be possible to include students in the sample if they did not take the SAT. The cell below builds a data frame of students who have taken the SAT and then finds the sample mean 10 times using a sample size of 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sat = df_combined[df_combined.LAST_SATI_VERB_SCORE.isna() == False]\n",
    "sample_size = 200\n",
    "means = []\n",
    "for i in range(10):\n",
    "    m = df_sat.GRADE.sample(sample_size).mean()\n",
    "    means.append(m)\n",
    "    print(\"Sample {} mean: {:0.2f}\".format(i, m))\n",
    "print(\"Sample mean range: {:0.2f} â€” {:0.2f}\".format(min(means), max(means)))\n",
    "print(\"Population mean: {:0.2f}\".format(pop_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 4\n",
    "How does the range of sample means compare to the case where samples were drawn from all students? Consider both the size of the range and its center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increasing Sample Size\n",
    "The above example showed that only sampling from students who have taken the SAT biases the sample mean to be higher than the population mean. Let's see if increasing the sample size helps at all. The below example chooses 10 random samples and calculates their means, this time including 5000 students in each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5000\n",
    "means = []\n",
    "for i in range(10):\n",
    "    m = df_sat.GRADE.sample(sample_size).mean()\n",
    "    means.append(m)\n",
    "    print(\"Sample {} mean: {:0.2f}\".format(i, m))\n",
    "print(\"Range: {:0.2f} â€” {:0.2f}\".format(min(means), max(means)))\n",
    "print(\"Population mean: {:0.2f}\".format(pop_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 5\n",
    "Does increasing the sample size improve the estimate of the population mean grade when the samples are only taken from students who completed the SAT?\n",
    "\n",
    "Compared to students who did not take the SAT, why might students who have taken the SAT have a higher grade point average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Correlations\n",
    "One of the most common tasks in quantitative analysis is to determine whether a relationship exists between two variables. When it does, those variables are said to be ___correlated___.\n",
    "\n",
    "One way to examine correlation is to plot the two variables against each other and look at the slope of the best fit line. A steep upward slope is called a positive correlation and means an increase in one variable usually corresponds to an increase in the other.\n",
    "\n",
    "A steep downward slope is called a negative correlation and means an increase in one variable usually corresponds to a decrease in the other.\n",
    "\n",
    "The cell below shows examples of various kinds of correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(r=0):\n",
    "    covs = [[1, r], [r, 1]]\n",
    "    x, y = np.random.multivariate_normal([0, 0], covs, 1000).T\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8 * 2/3))\n",
    "parameters = [\n",
    "    (0.9, 'Strong Positive'),\n",
    "    (0.6, 'Weak Positive'),\n",
    "    (0, 'No Correlation'),\n",
    "    (-0.6, 'Weak Negative'),\n",
    "    (-0.9, 'Strong Negative')\n",
    "]\n",
    "for i, (r, title) in enumerate(parameters):\n",
    "    x, y = generate_data(r)\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.plot(x, y, '.', markersize=4)\n",
    "    plt.title(title)\n",
    "    plt.xlim([-2, 2]); plt.ylim([-2, 2])\n",
    "    m, b, r, p, se = spstats.linregress(x, y)\n",
    "    plt.plot([min(x), max(x)], [min(x) * m + b, max(x) * m + b])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Spurious correlations\n",
    "Correlations are a good indication that two variables are related, but are not always conclusive. If you measure a large number of variables and compare each one to the others, you will find some that correlate purely by chance. These are called ___spurious correlations___.\n",
    "\n",
    "This section uses examples from Tyler Vigen's online directory of spurious correlations http://tylervigen.com/spurious-correlations. Each variable is a time series of 10 annual observations, such as the number of movies Nicolas Cage appeared in, or the number of Sociology PhDs awarded in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def show_correlation(pair):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    p, r, a, b = pair\n",
    "    df = a.join(b)\n",
    "    x, y = [df[c] for c in df.columns]\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot(x, y, '.', markersize=10)\n",
    "    plt.xlabel(a.columns[0])\n",
    "    plt.ylabel(b.columns[0])\n",
    "    \n",
    "def show_time_correlation(pair):\n",
    "    fig, ax2 = plt.subplots(1,1, figsize=(8,4))\n",
    "    p, r, a, b = pair\n",
    "    df = a.join(b)\n",
    "    x, y = [df[c] for c in df.columns]\n",
    "    ax2.set_xlabel('Year')\n",
    "    ax2.set_ylabel(a.columns[0])\n",
    "    lns2 = ax2.plot(df.index, x, 'or-', label=df.columns[0])\n",
    "    ax3 = ax2.twinx()\n",
    "    ax3.set_ylabel(b.columns[0])\n",
    "    lns3 = ax3.plot(df.index, y, 'sb-', label=df.columns[1])\n",
    "    lns = lns2 + lns3\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax2.legend(lns, labs, loc=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def plot_data(a):\n",
    "    a = a.set_index('Year')\n",
    "    fig, ax2 = plt.subplots(1,1, figsize=(8,4))\n",
    "    ax2.set_xlabel('Year')\n",
    "    ax2.set_ylabel('Count')\n",
    "    x = a[a.columns[0]]\n",
    "    lns2 = ax2.plot(a.index, x, 'sb-', label=a.columns[0])\n",
    "    lns = lns2\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax2.legend(lns, labs, loc=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def find_correlations(df):\n",
    "    correlations = []\n",
    "    for i in range(len(df)):\n",
    "        for j in range(i + 1, len(df)):\n",
    "            a = df[i].set_index('Year')\n",
    "            b = df[j].set_index('Year')\n",
    "            df_both = a.join(b)\n",
    "            x, y = [df_both[c] for c in df_both.columns]\n",
    "            r, p = spstats.pearsonr(x, y)\n",
    "            if p < 0.05:\n",
    "                correlations.append( (p, r, a, b))\n",
    "    return sorted(correlations, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"data/cage.csv\",\n",
    "    \"data/fall-pool.csv\",\n",
    "    \"data/steam.csv\",\n",
    "    \"data/bedsheets.csv\",\n",
    "    \"data/sociology.csv\",\n",
    "    \"data/cs.csv\",\n",
    "    \"data/economics.csv\",\n",
    "    \"data/anthropology.csv\"]\n",
    "df = [pd.read_csv(d) for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize data\n",
    "Now we can plot the various data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Correlations\n",
    "The following cell finds all pairs of data sets that are correlated with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = find_correlations(df)\n",
    "for i, (p, r, a, b) in enumerate(pairs):\n",
    "    print(i, ':', a.columns[0], 'â€”', b.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 6\n",
    "There code above compares 8 data sets. There are 28 possible pairs of data sets. What fraction of these pairs are correlated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Correlation\n",
    "The cells below visualize the correlation between variables in two different ways. The first plots one variable against the other. The next plots both variables over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_correlation(pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_time_correlation(pairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Prediction\n",
    "One common task in computational social science is to predict some feature of future data from data that has already been seen. This section will use the example of academic majors. Imagine you have access to the courses and grades of a group of students and want to determine what their current (or future) academic major is. This section will walk you through the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject grades\n",
    "We will be predicting academic majors based on Grade Points Earned, the sum of all course grades a student has achieved (also called Michigan Honor Points at the University of Michigan).\n",
    "\n",
    "Specifically, we will compare grade points earned within one subject (psychology) to grade points earned in other subjects. The cells below prepare the data by sorting it into psychology and non-psychology majors and producing a tuple of psychology and non-psychology grade points earned for each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "\n",
    "def get_data_subject(df_combined, subject):\n",
    "    df_a = df_combined[df_combined.MAJOR1_DESCR == subject]\n",
    "    df_b = df_combined[df_combined.MAJOR1_DESCR != subject]\n",
    "    return df_a, df_b\n",
    "\n",
    "def extract_features_subject(df, subject):\n",
    "    features = []\n",
    "    df_indexed = df.groupby(['ANONID', 'SUBJECT']).sum()\n",
    "    df_other = df[df.SUBJECT != subject].groupby('ANONID').sum()\n",
    "    for anonid in set(df.ANONID):\n",
    "        try:\n",
    "            grade_a = df_indexed.loc[(anonid, subject)].GRADE\n",
    "        except KeyError:\n",
    "            grade_a = 0\n",
    "        try:\n",
    "            grade_b = df_other.loc[anonid].GRADE\n",
    "        except KeyError:\n",
    "            grade_b = 0\n",
    "        features.append( (grade_a, grade_b) )\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data frames of psychology majors and other majors\n",
    "df_psych, df_other = get_data_subject(df_combined, \"Psychology BA\")\n",
    "# Convert data frames into features\n",
    "features_psych = extract_features_subject(df_psych, \"PSYCH\")[0:5000]\n",
    "features_other = extract_features_subject(df_other, \"PSYCH\")[0:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Visualize\n",
    "The cell below visualizes these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "x, y = zip(*features_other)\n",
    "plt.plot(x, y, 'o', markersize=1, color=\"#AFAF7F\", label=\"Psychology BA\")\n",
    "x, y = zip(*features_psych)\n",
    "plt.plot(x, y, 'o', markersize=1, color=\"#7F7FFF\", label=\"Other\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Grade Points Earned: Psychology\")\n",
    "plt.ylabel(\"Grade Points Earned: Non-Psychology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 7\n",
    "Looking at the above figure, how would you predict the major of student from their grade points earned?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Features\n",
    "The cell below combines the features for all students into a single list, and the corresponding academic major labels for students into another. These are the lists that will be used to predict academic majors and test our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import random\n",
    "X = features_psych + features_other\n",
    "y = [\"Psych\"] * len(features_psych) + [\"Other\"] * len(features_other)\n",
    "print(\"Feature:\", X[0])\n",
    "print(\"Label:\", y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Classifiers\n",
    "Now we will create a ___classifier___ to make predictions based on the features we have created. We first give the classifier a set of features with known labels, called training data. The classifier will use this to make future predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.95)\n",
    "classifier = SVC(kernel=\"linear\", probability=True)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing The Classifier\n",
    "The below cell picks a random feature (student) and predicts their label (academic major) using the classifier. It also prints out the correct academic major so we can see whether we were correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(X_test) - 1)\n",
    "sample = X_test[i]\n",
    "prediction = classifier.predict([sample])\n",
    "true = y_test[i]\n",
    "print(\"Psych grade points:\", sample[0])\n",
    "print(\"Other grade points:\", sample[1])\n",
    "print(\"Predicted:\\t\", prediction[0])\n",
    "print(\"True:\\t\\t\", true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer\n",
    "Run the above cell several times. When the classifier makes a mistake, is it usually predicting a student is a psychology major when they truly aren't? Or predicting other majors for true psychology majors? Or is it about 50/50?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Precision and Recall\n",
    "\n",
    "There are two ways to measure the quality of a classifier, based on the two types of errors it can make. Using psychology classes as an example, with a high ___precision___ classifier, you can be confident sample labeled as psychology is truly a psychology major. With a high ___recall___ classifier, you can be confident that nearly all of the psychology majors were detected. Most classifiers have a ___threshold___ that can be changed to alter the precision and recall. The cell below shows how the precision and recall varies with the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "\n",
    "def get_precision_recall(X, y, threshold, test_size=0.5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    classifier = SVC(kernel=\"linear\", probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred_proba = classifier.predict_proba(X_test)\n",
    "    y_pred = ['Psych' if x[1] > threshold else 'Other' for x in y_pred_proba]\n",
    "    precision = precision_score(y_test, y_pred, pos_label='Psych')\n",
    "    recall = recall_score(y_test, y_pred, pos_label='Psych')\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = []\n",
    "recall = []\n",
    "thresholds = []\n",
    "for threshold in tqdm([x / 10 for x in range(10)]):\n",
    "    p, r = get_precision_recall(X, y, threshold=threshold, test_size=0.95)\n",
    "    if p < 0.01 and r < 0.01:\n",
    "        continue\n",
    "    thresholds.append(threshold)\n",
    "    precision.append(p)\n",
    "    recall.append(r)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(thresholds, precision, label=\"Precision\")\n",
    "plt.plot(thresholds, recall, label=\"Recall\")\n",
    "plt.xlabel(\"Threshold\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 8\n",
    "Depending on the application, sometimes precision is more desirable and sometimes recall is more desirable. For example, if you were using a classifier to find likely locations of a rare lost treasure, you would want a high recall, to make sure you didn't miss possible locations.\n",
    "\n",
    "Can you think of one example where recall is more important and one where precision is more important? Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score\n",
    "It can be confusing to consider two separate measures of quality, so they are often combined into a single measure called the ___F1 score___. The cell below shows how F1 score changes along with precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weight\\tPrec.\\tRecall\\tF1\")\n",
    "f1 = [math.sqrt(precision[i] * recall[i]) for i in range(len(thresholds))]\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(thresholds, precision, label=\"Precision\")\n",
    "plt.plot(thresholds, recall, label=\"Recall\")\n",
    "plt.plot(thresholds, f1, label=\"F1\")\n",
    "plt.legend()\n",
    "plt.xlabel('Threshod')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with training data\n",
    "X_train = random.sample(features_psych, 2) + random.sample(features_other, 2)\n",
    "y_train = [\"Psych\"] * 2 + [\"Other\"] * 2\n",
    "classifier = SVC(kernel=\"linear\")\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_train)\n",
    "f1_score(y_train, y_pred, pos_label='Psych')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with out-of-sample data\n",
    "X_test = random.sample(features_psych, 50) + random.sample(features_other, 50)\n",
    "y_test = [\"Psych\"] * 50 + [\"Other\"] * 50\n",
    "y_pred = classifier.predict(X_test)\n",
    "f1_score(y_test, y_pred, pos_label='Psych')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "#### Reflection Question 1\n",
    "\n",
    "Consider a course where every student completing the course got an A. From only this information would you conclude that it would be easy to get an A in this class?\n",
    "\n",
    "The student performance data doesn't contain grades for students who withdrew from a course without completing it. Now, you learn that 75% of the students dropped the class after failing the midterm. Does that change your answer to the above question?\n",
    "\n",
    "Assuming that students only withdraw when they are performing poorly, how does the exclusion of students who have withdrawn from courses change the apparent student performance in a class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection Question 2\n",
    "In the first section of this lab, we saw that increasing the sample size decreased the range, or ___variance___, of estimates. We also saw that systematically excluding a group of indidividuals from the sample can raise or lower the entire range, called ___bias___.\n",
    "\n",
    "Can you think of an example where it is most important to reduce the variance, possibly at the expense of increasing bias?\n",
    "\n",
    "Can you think of an example where it is most important to reduce bias, possibly at the expense of increasing variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection Question 3\n",
    "Usually, the more data you use to train a classifier, the more accurate it will be. However, the less data you will have avaialbe to test on.\n",
    "\n",
    "What is the advantage of using a large amount of training data?\n",
    "\n",
    "What is the advantage of using a large amount of test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection Question 4\n",
    "Over the past decades, ___grade inflation___ has caused average course grades to steadily increase at many universites. Imagine you are using historical data to predict a current student's performance.\n",
    "\n",
    "How, if at all, could grade inflation increase the variance of the prediction?\n",
    "\n",
    "How, if at all, could grade inflation increase the bias of the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Matz, R. L., Koester, B. P., Fiorini, S., Grom, G., Shepard, L., Stangor, C. G., ... & McKay, T. A. (2017). Patterns of Gendered Performance Differences in Large Introductory Courses at Five Research Universities. AERA Open, 3(4), 2332858417743754.\n",
    "\n",
    "Wright, M. C., McKay, T., Hershock, C., Miller, K., & Tritz, J. (2014). Better than expected: Using learning analytics to promote student success in gateway science. Change: The Magazine of Higher Learning, 46(1), 28-34."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
