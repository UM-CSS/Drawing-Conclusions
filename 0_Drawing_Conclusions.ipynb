{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSS Lab: Drawing Conclusions\n",
    "This lab covers techniques for evaluating the validity of conclusions made from data. These conclusions are not always clear, and can have ethical implications. After completing this lab, you will understand some of the factors and methods used to evaluate the conclusions reached from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Background\n",
    "This lab uses data from the University of Michigan Learning Analytics Data Architecture (LARC) project. The LARC project tracks the performance of all undergraduate students at the University of Michigan. To protect the privacy of students, the true data is used to generate a synthetic data set: fake data that preserves the statistical properties of the original data. This data can be used to investigate questions about the performance of students over the course of their undergraduate career, taking factors such as major, gender, and year into account.\n",
    "\n",
    "## Section 2: Setup\n",
    "### 2.1 Load Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats as spstats\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load Data\n",
    "We begin by loading data about each (synthetic) student, and using the anonymous ID column (ANONID) as an index for the data frame. Some of the columns in this data frame are:\n",
    "\n",
    "* MAJOR1_DESCR - Student's first major\n",
    "* HSGPA - Student's high school GPA\n",
    "* LAST_ACT_COMP_SCORE - Student's comprehensive ACT score\n",
    "* LAST_SATI_TOTAL_SCORE - Student's total SAT score\n",
    "* SEX - Student's sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_student = pd.read_csv(\"data/student.record.csv.gz\").set_index(\"ANONID\")\n",
    "df_student.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading course data\n",
    "Now we load a separate data frame containing one row for each student/course combination. Some of the columns in this data frame are:\n",
    "\n",
    "* TERM - Academic term id\n",
    "* ANONID - Student id\n",
    "* SUBJECT - Course academic subject\n",
    "* CATALOG_NBR - Course catalog number (not unique across subjects)\n",
    "* GRADE - Student's grade in course\n",
    "* GPAO - Student's GPA up to and including current semester, excluding this course.\n",
    "* Season - Academic term season\n",
    "* Year - Acadeic term year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_course = pd.read_csv(\"data/course-modified.csv.gz\")\n",
    "df_course.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining Data\n",
    "Let's plot the high school GPAs of all students in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "df_student.HSGPA.hist(bins=np.arange(0.01,37.01))\n",
    "plt.xlabel('High School GPA'); plt.ylabel('Count')\n",
    "plt.yscale('log', nonposy='clip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 1\n",
    "The highest possible GPA is 4.0, but the above plot shows values above 30.\n",
    "These values must be errors. Give at least **two** possible explanations for how a value of 31 could end up in a student's GPA record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤” Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data\n",
    "We can do some data cleaning to remove values that are obvious errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "outliers = df_student.HSGPA > 4\n",
    "df_student.loc[outliers] = None\n",
    "# Remove missing data coded as 0\n",
    "missing = df_student.HSGPA == 0\n",
    "df_student.loc[missing] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "df_student.HSGPA.hist(bins=25)\n",
    "plt.xlabel('High School GPA'); plt.ylabel('Count')\n",
    "plt.yscale('log', nonposy='clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# More data cleaning\n",
    "\n",
    "outliers = df_course.GRADE > 4\n",
    "df_course.loc[outliers] = None\n",
    "missing = np.isnan(df_course.GRADE)\n",
    "df_course = df_course.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Combining Data\n",
    "We can join the student and course data into a single data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_course.join(df_student, on=\"ANONID\")\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Sampling\n",
    "Often, data is collected from a small group in order to try to understand a larger group. For example, asking 100 random students to complete a survey in order to understand the entire student body. This process is called _sampling_. The data collected is called the ___sample___ and the larger group is the ___target population___."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def get_bins(values):\n",
    "    values = sorted(set(values))\n",
    "    midpoints = [np.mean((values[i],values[i+1])) for i, g in enumerate(values[:-1])]\n",
    "    left = values[0] - (midpoints[0] - values[0])\n",
    "    right = values[-1] + (values[-1] - midpoints[-1])\n",
    "    bins = [left] + midpoints + [right]\n",
    "    return bins\n",
    "\n",
    "grade_hist_bins = get_bins(df_course.GRADE)\n",
    "all_grades = sorted(set(df_course.GRADE))\n",
    "\n",
    "def get_sample_mean(df, num_samples=10):\n",
    "    samples = df.GRADE.dropna().sample(num_samples, replace=True)\n",
    "    return samples.mean()\n",
    "\n",
    "def grade_hist(grades, color=(0,0,1,0.5)):\n",
    "    n, bins, patches = plt.hist(grades, align=\"mid\", bins=grade_hist_bins, width=0.1, color=color)\n",
    "    plt.xticks(range(5), ['E', 'D', 'C', 'B', 'A'])\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(\"Grade\")\n",
    "    \n",
    "def grade_stem(grades, color=(0,0,1,0.5)):\n",
    "    bin_values, bins = np.histogram(grades, grade_hist_bins)\n",
    "    plt.stem(all_grades, bin_values, basefmt=\"none\", use_line_collection = True)\n",
    "    plt.xticks(range(5), ['E', 'D', 'C', 'B', 'A'])\n",
    "    ylim = plt.ylim()\n",
    "    plt.ylim([0, ylim[1]])\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(\"Grade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Sample Size\n",
    "\n",
    "#### Population Mean\n",
    "In this section, we will use the example of finding the mean course grade of students in the LARC data set. Since we have data on all students rather than just a sample, we can calculate the exact mean of all students, called the ___population mean___, but usually that's not possible. The cell below calculates the exact mean, which will be helpful to keep in mind throught this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mean = df_course.GRADE.mean()\n",
    "pop_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling\n",
    "Now let's pretend we do not have access to everyone's grades. This is a really common situation, and it is why people conduct surveys. It is often much easier to ask a smaller group of people (called a sample) for information like grades than to get data on every single person (called the population). We can then use the group's answers to estimate everyone's answers. That is, we estimate the population data using the sample data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 2\n",
    "In the cells below, you will be exploring how sample size influences sample mean. In the cell below, change the sample size to answer the following questions:\n",
    "1. What sample sizes did you try?\n",
    "2. How does the range of sample means change as sample size changes?\n",
    "3. Which letter grade or grades do these ranges correspond to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the value of sample size\n",
    "sample_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell simulates an experiment that samples random course grades from the number of students indicated by ```sample_size``` and calculates their mean, called the sample mean. This is like asking this number of random students their grades. The figure shows the grades sampled and is labeled with the sample mean. You can repeat this cell to see different random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = df_course.GRADE.sample(sample_size)\n",
    "plt.figure(figsize=(8,4))\n",
    "grade_stem(samples)\n",
    "plt.title(\"Sample mean: {:0.2f}\".format(np.mean(samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Mean\n",
    "The cell below repeats that process (take a sample of three random grades and take the mean) 10 times. Then it shows the range of sample means as well as the true population mean so that you can see how close (or far) the sample means are from the population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "for i in range(10):\n",
    "    m = df_course.GRADE.sample(sample_size).mean()\n",
    "    means.append(m)\n",
    "    print(\"Sample {} mean: {:0.2f}\".format(i ,m))\n",
    "print(\"Sample mean range: {:0.2f} â€” {:0.2f}\".format(min(means), max(means)))\n",
    "print(\"Population mean: {:0.2f}\".format(pop_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Sample Bias\n",
    "In the previous section, we saw that estimates based on samples depend on the size of the sample. In this section, we explore what happens if a sample is drawn from a subset the population, rather than the entire population. For comparison, the cell below shows the true population mean of all course grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Frame\n",
    "The ___sampling frame___ is the set of people samples come from. Ideally, the sampling frame should be the entire population, but that may not always be possible.\n",
    "\n",
    "As an example, let's assume that we're conducting a survey of student grades and are sampling student names from SAT records. Not all students took the SAT. So the set of students who might be sampled (the sampling frame) is smaller than the set of all students (the population)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 3\n",
    "The cells below select students who have taken the SAT and then takes 10 samples of students of size ```sample_size``` and reports the means for each sample. Use the cells below to answer the following:\n",
    "1. How does the range of sample means compare to the case where samples were drawn from all students? Consider both the size of the range and its center.\n",
    "2. Does increasing the sample size improve the estimate of the population mean grade when the samples are only taken from students who completed the SAT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the value of sample size\n",
    "sample_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sat = df_combined[df_combined.LAST_SATI_VERB_SCORE.notnull()]\n",
    "means = []\n",
    "for i in range(10):\n",
    "    m = df_sat.GRADE.sample(sample_size).mean()\n",
    "    means.append(m)\n",
    "    print(\"Sample {} mean: {:0.2f}\".format(i, m))\n",
    "print(\"Sample mean range: {:0.2f} â€” {:0.2f}\".format(min(means), max(means)))\n",
    "print(\"Population mean: {:0.2f}\".format(pop_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 4\n",
    "Compared to students who did not take the SAT, why might students who have taken the SAT have a higher grade point average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Correlations\n",
    "One of the most common tasks in quantitative analysis is to determine whether a relationship exists between two variables. When it does, those variables are said to be ___correlated___.\n",
    "\n",
    "One way to examine correlation is to plot the two variables against each other and look at the slope of the best fit line. A upward slope is called a positive correlation and means an increase in one variable usually corresponds to an increase in the other.\n",
    "\n",
    "A downward slope is called a negative correlation and means an increase in one variable usually corresponds to a decrease in the other.\n",
    "\n",
    "The cell below shows examples of various kinds of correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot(theta):\n",
    "    theta = np.deg2rad(theta)\n",
    "    return np.array([\n",
    "        [np.cos(theta), -np.sin(theta)],\n",
    "        [np.sin(theta), np.cos(theta)]\n",
    "    ])\n",
    "\n",
    "def getcov(corr=1, slope=1, theta=0):\n",
    "    cov = np.array([\n",
    "        [1/slope, corr],\n",
    "        [corr, slope]\n",
    "    ])\n",
    "\n",
    "    r = rot(theta)\n",
    "    return r @ cov @ r.T\n",
    "\n",
    "def generate_data(x=0, y=0, corr=1, slope=1, theta=0):\n",
    "    # get the covariance matrix with the appropriate transforms\n",
    "    cov = getcov(corr=corr, slope=slope, theta=theta)\n",
    "    X, Y = np.random.multivariate_normal([x, y], cov, 2000).T   \n",
    "    return X, Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7.5))\n",
    "parameters = [\n",
    "    (0.9, 'Strong Positive'),\n",
    "    (0.5, 'Weak Positive'),\n",
    "    (0.0, 'No Correlation'),\n",
    "    (-0.5, 'Weak Negative'),\n",
    "    (-0.9, 'Strong Negative')\n",
    "]\n",
    "\n",
    "for i, (r, title) in enumerate(parameters):\n",
    "    x, y = generate_data(corr=r,slope=1)\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.plot(x, y, '.', markersize=4)\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    plt.title(title + \" (\"+str(r)+\")\")\n",
    "    plt.xlim([-2, 2])\n",
    "    plt.ylim([-2, 2])\n",
    "\n",
    "slopes = [0.5, 1, 1.5, -0.5 , -1]\n",
    "fixed_corr = 1\n",
    "\n",
    "for i, slope in enumerate(slopes):\n",
    "    x, y = generate_data(corr=fixed_corr,slope=slope)\n",
    "    plt.subplot(2, 5, i + 6)\n",
    "    plt.plot(x, y, '.', markersize=4)\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    plt.title(\"Correlation = \" + str(np.sign(slope)))\n",
    "    plt.xlim([-2, 2])\n",
    "    plt.ylim([-2, 2])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Spurious correlations\n",
    "Correlations are a good indication that two variables are related, but are not always conclusive. If you measure a large number of variables and compare each one to the others, you will find some that correlate purely by chance. These are called ___spurious correlations___.\n",
    "\n",
    "This section uses examples from Tyler Vigen's online directory of spurious correlations http://tylervigen.com/spurious-correlations. Each variable is a time series of 10 annual observations, such as the number of movies Nicolas Cage appeared in, or the number of Sociology PhDs awarded in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def show_correlation(pair):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    p, r, a, b = pair\n",
    "    df = a.join(b)\n",
    "    x, y = [df[c] for c in df.columns]\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot(x, y, '.', markersize=10)\n",
    "    plt.xlabel(a.columns[0])\n",
    "    plt.ylabel(b.columns[0])\n",
    "    \n",
    "def show_time_correlation(pair):\n",
    "    fig, ax2 = plt.subplots(1,1, figsize=(8,4))\n",
    "    p, r, a, b = pair\n",
    "    df = a.join(b)\n",
    "    x, y = [df[c] for c in df.columns]\n",
    "    ax2.set_xlabel('Year')\n",
    "    ax2.set_ylabel(a.columns[0])\n",
    "    lns2 = ax2.plot(df.index, x, 'or-', label=df.columns[0])\n",
    "    ax3 = ax2.twinx()\n",
    "    ax3.set_ylabel(b.columns[0])\n",
    "    lns3 = ax3.plot(df.index, y, 'sb-', label=df.columns[1])\n",
    "    lns = lns2 + lns3\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax2.legend(lns, labs, loc=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def plot_data(a):\n",
    "    a = a.set_index('Year')\n",
    "    fig, ax2 = plt.subplots(1,1, figsize=(8,4))\n",
    "    ax2.set_xlabel('Year')\n",
    "    ax2.set_ylabel('Count')\n",
    "    x = a[a.columns[0]]\n",
    "    lns2 = ax2.plot(a.index, x, 'sb-', label=a.columns[0])\n",
    "    lns = lns2\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax2.legend(lns, labs, loc=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def find_correlations(df):\n",
    "    correlations = []\n",
    "    for i in range(len(df)):\n",
    "        for j in range(i + 1, len(df)):\n",
    "            a = df[i].set_index('Year')\n",
    "            b = df[j].set_index('Year')\n",
    "            df_both = a.join(b)\n",
    "            x, y = [df_both[c] for c in df_both.columns]\n",
    "            r, p = spstats.pearsonr(x, y)\n",
    "            if p < 0.05:\n",
    "                correlations.append( (p, r, a, b))\n",
    "    return sorted(correlations, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"data/cage.csv\",\n",
    "    \"data/fall-pool.csv\",\n",
    "    \"data/steam.csv\",\n",
    "    \"data/bedsheets.csv\",\n",
    "    \"data/sociology.csv\",\n",
    "    \"data/cs.csv\",\n",
    "    \"data/economics.csv\",\n",
    "    \"data/anthropology.csv\"]\n",
    "df = [pd.read_csv(d) for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize data\n",
    "Now we can plot the various data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(df[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Correlations\n",
    "The following cell compares each of the 8 data sets with all of the others and lists the pairs that are significantly correlated with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = find_correlations(df)\n",
    "for i, (p, r, a, b) in enumerate(pairs):\n",
    "    print(i, ':', a.columns[0], 'â€”', b.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 5\n",
    "There code above compares all 28 possible combinations of the 8 data sets and lists just the ones with significant correlations. What fraction of these combinations are correlated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Correlation\n",
    "The cells below visualize the correlation between variables in two different ways. The first plots one variable against the other. The next plots both variables over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_correlation(pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_time_correlation(pairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Prediction\n",
    "One common task in computational social science is to predict some feature of future data from data that has already been seen. This section will use the example of academic majors. Imagine you have access to the courses and grades of a group of students and want to determine what their current (or future) academic major is. This section will walk you through the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject grades\n",
    "We will be predicting academic majors based on Grade Points Earned, the sum of all course grades a student has achieved (also called Michigan Honor Points at the University of Michigan).\n",
    "\n",
    "Specifically, we will compare grade points earned within one subject (psychology) to grade points earned in other subjects. The cells below prepare the data by sorting it into psychology and non-psychology majors and producing a tuple of psychology and non-psychology grade points earned for each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings\n",
    "df_combined.rename(columns={'LAST_ACT_ENGL_SCORE': 'ACT_ENGLISH', \n",
    "                            'LAST_ACT_MATH_SCORE': 'ACT_MATH',\n",
    "                            'LAST_ACT_READ_SCORE': 'ACT_READING', \n",
    "                            'LAST_ACT_SCIRE_SCORE': 'ACT_WRITING',\n",
    "                            'LAST_ACT_COMP_SCORE': 'ACT_SCORE',\n",
    "                            'LAST_SATI_VERB_SCORE': 'SAT_VERBAL',\n",
    "                            'LAST_SATI_MATH_SCORE': 'SAT_MATH',\n",
    "                            'LAST_SATI_TOTAL_SCORE': 'SAT_TOTAL'}, inplace=True)\n",
    "\n",
    "major = 'Psychology BA'\n",
    "subject = 'PSYCH'\n",
    "n = 5000\n",
    "variables = ['ANONID', 'major', 'HSGPA', 'SEX',\n",
    "             'ACT_ENGLISH', 'ACT_MATH', 'ACT_READING', 'ACT_WRITING',\n",
    "             'ACT_SCORE', 'SAT_VERBAL', 'SAT_MATH', 'SAT_TOTAL']\n",
    "\n",
    "# make sex numeric (1 == female)\n",
    "df_combined.SEX.replace({'F':1, 'M':0}, inplace=True)\n",
    "\n",
    "# categorize students and classes\n",
    "df_combined['major'] = (df_combined.MAJOR1_DESCR == major).astype(int)\n",
    "df_combined.major.replace({1:major, 0:'Other'}, inplace=True)\n",
    "df_combined['on_topic'] = (df_combined.SUBJECT == subject).astype(int)\n",
    "\n",
    "#Get total grades in the subject\n",
    "topical = df_combined[df_combined.on_topic == 1][variables + ['GRADE']]\n",
    "topical = topical.groupby(variables).sum().reset_index()\n",
    "topical.rename(columns={'GRADE':'subject_grade'}, inplace=True)\n",
    "\n",
    "#get total grades in other subjects\n",
    "ot = df_combined[df_combined.on_topic == 0][['ANONID', 'GRADE']]\n",
    "ot = ot.groupby(['ANONID']).sum().reset_index()\n",
    "ot.rename(columns={'GRADE':'other_grade'}, inplace=True)\n",
    "\n",
    "#merge grade info together\n",
    "together = topical.merge(ot, on='ANONID')\n",
    "\n",
    "#sample for balanced classes\n",
    "majors = together[together.major == major].sample(n, replace=True)\n",
    "others = together[together.major != major].sample(n, replace=True)\n",
    "together = pd.concat([majors, others], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Visualize\n",
    "The cell below visualizes these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "for m in together.major.unique():\n",
    "    tmp = together[together.major == m]\n",
    "    plt.scatter(tmp.subject_grade, tmp.other_grade, s=2, label=m)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Grade Points Earned in \"+subject)\n",
    "plt.ylabel(\"Grade Points Earned in Other Subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 6\n",
    "Looking at the above figure, how would you predict the major of student from their grade points earned?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Features\n",
    "The cell below combines the grade points for all students into one list, and the corresponding academic major labels for students into another. These are the lists that will be used to predict academic majors and test our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = together[['subject_grade', 'other_grade']]\n",
    "y = together['major']\n",
    "print(\"Features: \", X.values[0])\n",
    "print(\"Label:\", y.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Classifiers\n",
    "Now we will create a ___classifier___ to make predictions based on the features we have created. We first give the classifier a set of features with known labels, called training data. We're asking the classifier to figure out some pattern in the input data, grade points in different subjects, that is related to the thing we want to know, a student's major. Once it learns this pattern (for now, don't worry about how it learns), it can tell us things like, \"given these grade points, I think the student is a psychology major.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.95)\n",
    "classifier = SVC(kernel=\"linear\", probability=True)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing The Classifier\n",
    "The below cell picks a random student and predicts their major using the classifier. It also prints out the correct academic major so we can see whether the classifier is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0, len(X_test) - 1)\n",
    "sample = X_test.values[i]\n",
    "prediction = classifier.predict([sample])\n",
    "true = y_test.values[i]\n",
    "print(subject+\" grade points:\", sample[0])\n",
    "print(\"Other grade points:\", sample[1])\n",
    "print(\"Predicted:\\t\", prediction[0])\n",
    "print(\"True:\\t\\t\", true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 7\n",
    "Run the above cell several times. When the classifier makes a mistake, is it usually predicting a student is a psychology major when they aren't? Or predicting psychology majors are other majors? Or is it about 50/50?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Errors\n",
    "The cell below calculates the number of Psychology majors correctly classified (True Positive), the number of Other majors correctly classified (True Negative), Psychology majors classified as Other (False Negative), and Other majors classified as Psychology majors (False Positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.predict(X_test)\n",
    "\n",
    "true_positive = sum((prediction == 'Psychology BA') & (y_test == 'Psychology BA'))\n",
    "false_positive = sum((prediction == 'Psychology BA') & (y_test == 'Other'))\n",
    "true_negative = sum((prediction == 'Other') & (y_test == 'Other'))\n",
    "false_negative = sum((prediction == 'Other') & (y_test == 'Psychology BA'))\n",
    "\n",
    "print('Number of Psychology BAs predicted to be Psychology BAs: ', true_positive)\n",
    "print('Number of Psychology BAs predicted to be Other: ', false_negative)\n",
    "print('Number of Other majors predicted to be Other: ', true_negative)\n",
    "print('Number of Other majors predicted to be Psychology BAs: ', false_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Precision and Recall\n",
    "\n",
    "There are several ways to measure the quality of a classifier. We will talk about ___precision___ and ___recall___. Using psychology classes as an example, \n",
    "- With a high ___precision___ classifier, we can be confident that anyone it says is a psychology major really is one. \n",
    "\n",
    "$$ \\text{Precision} = \\frac{\\text{True Positive}}{\\text{True Positive} + \\text{False Positive}} $$\n",
    "\n",
    "- With a high ___recall___ classifier, we can be confident that none of the psychology majors were labeled as another major.\n",
    "\n",
    "$$ \\text{Recall} = \\frac{\\text{True Positive}}{\\text{True Positive} + \\text{False Negative}} $$\n",
    "\n",
    "- An ideal classifier would have high precision and high recall, but a bad one might have neither. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 8\n",
    "Using the values above, calculate the precision and recall of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, there is a tradeoff between precision and recall. \n",
    "- If a model says that every student is a psychology major, for example, then it would have perfect recall (all psych majors correctly guessed as psych majors), but terrible precision (all non-psych majors are also guessed as psych majors).\n",
    "- If it labels only the most likely psychology major as a psychology major, then it probably has good precision (one out of one, or 100% of guesses correct), but it will have terrible recall (most psychology majors listed as other majors).\n",
    "- We can look at this tradeoff by changing the \"threshold\" of the classifier, shown in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def get_proba(X, y, test_size=0.5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    classifier = SVC(kernel=\"linear\", probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred_proba = classifier.predict_proba(X_test)\n",
    "    return y_test, y_pred_proba[:,1]\n",
    "\n",
    "def get_precision_recall(y_true, y_proba, threshold):\n",
    "    y_pred = [major if x > threshold else 'Other' for x in y_proba]\n",
    "    precision = precision_score(y_true, y_pred, pos_label=major)\n",
    "    recall = recall_score(y_true, y_pred, pos_label=major)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = []\n",
    "recall = []\n",
    "thresholds = np.arange(0,1,.05)\n",
    "\n",
    "y_true, y_proba = get_proba(X, y, test_size=0.95)\n",
    "\n",
    "for threshold in tqdm(thresholds):\n",
    "    p, r = get_precision_recall(y_true, y_proba, threshold=threshold)\n",
    "    precision.append(p)\n",
    "    recall.append(r)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(thresholds, precision, label=\"Precision\")\n",
    "plt.plot(thresholds, recall, label=\"Recall\")\n",
    "plt.xlabel(\"Threshold\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Answer 9\n",
    "Depending on the application, sometimes precision is more desirable and sometimes recall is more desirable. For example, if you were using a classifier to find likely locations of a rare lost treasure, you would want a high recall, to make sure you didn't miss possible locations.\n",
    "\n",
    "Can you think of **one** example where recall is more important and **one** where precision is more important? Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score\n",
    "It can be confusing to consider two separate measures of quality, so they are sometimes combined into a single measure called the ___F1 score___. The cell below shows how F1 score changes along with precision and recall.\n",
    "\n",
    "$$ F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weight\\tPrec.\\tRecall\\tF1\")\n",
    "f1 = [2 * precision[i] * recall[i] / (precision[i] + recall[i]) for i in range(len(thresholds))]\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(thresholds, precision, label=\"Precision\")\n",
    "plt.plot(thresholds, recall, label=\"Recall\")\n",
    "plt.plot(thresholds, f1, label=\"F1\")\n",
    "plt.legend()\n",
    "plt.xlabel('Threshod')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with training data\n",
    "n = 4\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size=n, \n",
    "                                                    test_size=X.shape[0]-n, \n",
    "                                                    stratify=y)\n",
    "classifier = SVC(kernel=\"linear\")\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_train)\n",
    "print(\"F-1 score for the training data is: \", f1_score(y_train, y_pred, pos_label=major))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with out-of-sample data\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"F-1 score for the testing data is: \", f1_score(y_test, y_pred, pos_label=major))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflect and Try it Yourself\n",
    "\n",
    "In the previous section, we built a classifier that used grade points earned in psychology courses and grade points earned in other courses to predict whether a student is a Psychology BA or Other major. Now it's your turn to build a classifier. We can use the other variables in our data to try and improve our classifier. Your goal will be to build a classifier that outperforms the previous classifier. This is to say that you will evaluate your classifier's precision, recall, and F1 scores and argue why your classifier is better.\n",
    "\n",
    "In this section, you should choose 1 or more variables to use as predicting variables instead of (or alongside of) grade points.\n",
    "\n",
    "Here are the variables you can choose from:\n",
    "\n",
    "``subject_grade`` <br>\n",
    "``other_grade`` <br>\n",
    "``HSGPA`` <br>\n",
    "``SEX`` <br>\n",
    "``ACT_ENGLISH`` <br>\n",
    "``ACT_MATH`` <br>\n",
    "``ACT_READING`` <br>\n",
    "``ACT_WRITING`` <br>\n",
    "``ACT_SCORE`` <br>\n",
    "``SAT_VERBAL`` <br>\n",
    "``SAT_MATH`` <br>\n",
    "``SAT_TOTAL`` <br>\n",
    "\n",
    "In the following cell, write the name of each variable you would like to use in a list. Each item should be in quotations and separated by a comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the variables you would like to include in your classifier\n",
    "# x_vars = ['subject_grade', 'other_grade'] these are the variables we used earlier\n",
    "\n",
    "# enter your choice of variables in quotes, separated by a comma\n",
    "x_vars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the classifier\n",
    "X = together[x_vars]\n",
    "y = together['major']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.95)\n",
    "classifier = SVC(kernel=\"linear\", probability=True)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_train)\n",
    "print(\"Precision for the training data is: \", precision_score(y_train, y_pred, pos_label=major))\n",
    "print(\"Recall for the training data is: \", recall_score(y_train, y_pred, pos_label=major))\n",
    "print(\"F-1 score for the training data is: \", f1_score(y_train, y_pred, pos_label=major))\n",
    "\n",
    "# Test with out-of-sample data\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Precision for the testing data is: \", precision_score(y_test, y_pred, pos_label=major))\n",
    "print(\"Recall for the testing data is: \", recall_score(y_test, y_pred, pos_label=major))\n",
    "print(\"F-1 score for the testing data is: \", f1_score(y_test, y_pred, pos_label=major))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection Question 1\n",
    "\n",
    "1. In the Try it Yourself section, what variables did you use to build your classifier?\n",
    "2. What are the precision, recall, and F1 scores for your classifier for the training data?\n",
    "3. What are the precision, recall, and F1 scores for your classifier for the testing data?\n",
    "4. The goal was to build a classifier that performs better than our earlier classifier. Why is your classifier better? (Hint: Which measure(s) do you consider to be most important for this classification task?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection Question 2\n",
    "\n",
    "1. Consider a course where every student completing the course got an A. From only this information would you conclude that it would be easy to get an A in this class?\n",
    "2. The student performance data doesn't contain grades for students who withdrew from a course without completing it. Now, you learn that 75% of the students dropped the class after failing the midterm. Does that change your answer to the above question?\n",
    "3. Assuming that students only withdraw when they are performing poorly, how does the exclusion of students who have withdrawn from courses change the apparent student performance in a class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection Question 3\n",
    "In the first section of this lab, we saw that increasing the sample size decreased the range, or ___variance___, of estimates. We also saw that systematically excluding a group of indidividuals from the sample can raise or lower the entire range, called ___bias___.\n",
    "\n",
    "Over the past decades, ___grade inflation___ has caused average course grades to steadily increase at many universites. Imagine you are using historical data to predict a current student's performance.\n",
    "\n",
    "1. How, if at all, could grade inflation increase the variance of the prediction?\n",
    "2. How, if at all, could grade inflation increase the bias of the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection Question 4\n",
    "Usually, the more data you use to train a classifier, the more accurate it will be. However, the less data you will have available to test on.\n",
    "\n",
    "1. What is the advantage of using a large amount of training data?\n",
    "2. What is the advantage of using a large amount of test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¤”Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Matz, R. L., Koester, B. P., Fiorini, S., Grom, G., Shepard, L., Stangor, C. G., ... & McKay, T. A. (2017). Patterns of Gendered Performance Differences in Large Introductory Courses at Five Research Universities. AERA Open, 3(4), 2332858417743754.\n",
    "\n",
    "Wright, M. C., McKay, T., Hershock, C., Miller, K., & Tritz, J. (2014). Better than expected: Using learning analytics to promote student success in gateway science. Change: The Magazine of Higher Learning, 46(1), 28-34."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
